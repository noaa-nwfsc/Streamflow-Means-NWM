{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fd8601-2926-4b92-afe0-6715827f705b",
   "metadata": {},
   "source": [
    "# GCP Package structure"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8384c848-2b74-4a00-b778-7a2c2cbd8a5a",
   "metadata": {},
   "source": [
    "bucket/\n",
    "└── huc18/                           \n",
    "    ├── flowline/                   # All vector data for the region\n",
    "    │   ├── WR_18_Flowline.parquet\n",
    "    │   ├── WR_18_metadata.parquet\n",
    "    │   └── README.md               \n",
    "    │\n",
    "    ├── streamflow/                 # NetCDF and Zarr files\n",
    "    │   ├── netcdf/\n",
    "    │   └── zarr/\n",
    "    │\n",
    "    ├── notebooks/                  # Reproducibility and how-to examples\n",
    "    │   ├── package_structure.ipynb\n",
    "    │   ├── shapefile_processing.ipynb\n",
    "    │   ├── streamflow_processing.ipynb\n",
    "    │   ├── save_to_gcp.ipynb\n",
    "    │   └── README.md               \n",
    "    │\n",
    "    └── metadata/                   # Additional documentation\n",
    "        ├── wr18_hydro_metadata.json\n",
    "        └── README.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26df42-aeb3-406a-a503-99f72af6fc56",
   "metadata": {},
   "source": [
    "## Upload to GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae458e86-ff30-400c-8ff3-201508efe8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up bucket client\n",
    "# stop annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Your application has authenticated using end user credentials\")\n",
    "\n",
    "from google.cloud import storage\n",
    "from pathlib import Path\n",
    "\n",
    "# Create client and bucket\n",
    "bucket_name = \"nmfs_odp_nwfsc\"\n",
    "client = storage.Client(project=\"noaa-gcs-public-data\")\n",
    "bucket = client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56356449-d1dc-4f16-b352-171f878bd704",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2e3289-785a-41b4-a633-e3b2e7dd282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded wr18_hydro_metadata.json to gs://nmfs_odp_nwfsc/CB/nwm_daily_means/wr18/metadata/wr18_hydro_metadata.json\n",
      "✅ Uploaded README.md to gs://nmfs_odp_nwfsc/CB/nwm_daily_means/wr18/metadata/README.md\n",
      "✅ Uploaded wr18_map.png to gs://nmfs_odp_nwfsc/CB/nwm_daily_means/wr18/metadata/wr18_map.png\n"
     ]
    }
   ],
   "source": [
    "# Local metadata folder\n",
    "data_dir = Path(\"../metadata\")\n",
    "destination_prefix = \"CB/nwm_daily_means/wr18/metadata\"\n",
    "\n",
    "# Upload each file, skipping unwanted directories and hidden files\n",
    "for file_path in data_dir.glob(\"*\"):\n",
    "    if file_path.is_file() and \".ipynb_checkpoints\" not in str(file_path):\n",
    "        blob_path = f\"{destination_prefix}/{file_path.name}\"\n",
    "        blob = bucket.blob(blob_path)\n",
    "        blob.upload_from_filename(str(file_path))\n",
    "        print(f\"✅ Uploaded {file_path.name} to gs://{bucket_name}/{blob_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9706e5-0efa-46d4-9660-effab319be2c",
   "metadata": {},
   "source": [
    "## flowline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b191a6-d604-4358-9382-d2670bbdaf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded WR_18_Flowline.parquet to gs://nmfs_odp_nwfsc/CB/nwm_daily_means/wr18/flowline/WR_18_Flowline.parquet\n",
      "✅ Uploaded WR_18_metadata.parquet to gs://nmfs_odp_nwfsc/CB/nwm_daily_means/wr18/flowline/WR_18_metadata.parquet\n",
      "✅ Uploaded README.md to gs://nmfs_odp_nwfsc/CB/nwm_daily_means/wr18/flowline/README.md\n"
     ]
    }
   ],
   "source": [
    "# Local flowline folder\n",
    "data_dir = Path(\"../flowline\")\n",
    "destination_prefix = \"CB/nwm_daily_means/wr18/flowline\"\n",
    "\n",
    "# Upload each file, skipping unwanted directories and hidden files\n",
    "for file_path in data_dir.glob(\"*\"):\n",
    "    if file_path.is_file() and \".ipynb_checkpoints\" not in str(file_path):\n",
    "        blob_path = f\"{destination_prefix}/{file_path.name}\"\n",
    "        blob = bucket.blob(blob_path)\n",
    "        blob.upload_from_filename(str(file_path))\n",
    "        print(f\"✅ Uploaded {file_path.name} to gs://{bucket_name}/{blob_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526415a-9eff-4cc4-95c6-c928b7ea9a6b",
   "metadata": {},
   "source": [
    "## notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726214c-b366-4850-b605-48d9907daf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../notebooks\")\n",
    "destination_prefix = \"CB/nwm_daily_means/wr18/notebooks\"\n",
    "\n",
    "# Upload each file, skipping unwanted directories and hidden files\n",
    "for file_path in data_dir.glob(\"*\"):\n",
    "    if file_path.is_file() and \".ipynb_checkpoints\" not in str(file_path):\n",
    "        blob_path = f\"{destination_prefix}/{file_path.name}\"\n",
    "        blob = bucket.blob(blob_path)\n",
    "        blob.upload_from_filename(str(file_path))\n",
    "        print(f\"✅ Uploaded {file_path.name} to gs://{bucket_name}/{blob_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
